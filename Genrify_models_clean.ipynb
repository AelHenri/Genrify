{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genrify Project - Phase II\n",
    "## Music genre prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Henri Toussaint<br>\n",
    "Victor Saint Guilhem<br>\n",
    "Beno√Æt Lafon<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project sets out to predict the genre of a music using the Spotify API, which provides audio features for each tracks. To collect the tracks, we used a recommandation function with a genre seed. We handpicked 20 genres in order to best represent tracks, and from each genre, we collected 100 tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from genrify_module import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"music_collection.csv\")\n",
    "#data = data.iloc[np.random.permutation(len(data))]\n",
    "pd_attributes = data.loc[:,'acousticness':'valence']\n",
    "attributes = np.array(pd_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 2000\n",
      "Number of attributes: 13\n",
      "Attributes:\n",
      "\tacousticness\n",
      "\tdanceability\n",
      "\tduration_ms\n",
      "\tenergy\n",
      "\tinstrumentalness\n",
      "\tkey\n",
      "\tliveness\n",
      "\tloudness\n",
      "\tmode\n",
      "\tspeechiness\n",
      "\ttempo\n",
      "\ttime_signature\n",
      "\tvalence\n"
     ]
    }
   ],
   "source": [
    "print('Number of instances: ' + str(data.shape[0]))\n",
    "print('Number of attributes: ' + str(pd_attributes.shape[1]))\n",
    "print('Attributes:')\n",
    "for i in pd_attributes.columns.values:\n",
    "    print('\\t'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_attributes = scale(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENRES = ['alternative','blues','classical','country','electro','folk','french','hard-rock','heavy-metal','hip-hop','indie','jazz','pop','psych-rock','punk-rock','r-n-b','reggae','rock','soul','techno']\n",
    "target_multinomial = []\n",
    "for i in data['genre']:\n",
    "    target_multinomial.append(GENRES.index(i))\n",
    "target_multinomial=np.array(target_multinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Decision Tree Accuracy: 0.036\n"
     ]
    }
   ],
   "source": [
    "random_model = DummyClassifier(strategy='uniform')\n",
    "\n",
    "random_acc_scores = cross_val_score(random_model, sc_attributes, target_multinomial,cv=10)\n",
    "avg_random_acc = np.mean(random_acc_scores)\n",
    "print(\"Averaged Decision Tree Accuracy: \" + str(avg_random_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Decision Tree Accuracy: 0.05\n"
     ]
    }
   ],
   "source": [
    "majo_model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "majo_acc_scores = cross_val_score(majo_model, sc_attributes, target_multinomial,cv=10)\n",
    "avg_majo_acc = np.mean(majo_acc_scores)\n",
    "print(\"Averaged Decision Tree Accuracy: \" + str(avg_majo_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sc_attributes, target_multinomial, train_size=0.67, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for c=0.01: 0.335\n",
      "Averaged accuracy for c=0.1: 0.359\n",
      "Averaged accuracy for c=1: 0.3655\n",
      "Averaged accuracy for c=2: 0.366\n",
      "Averaged accuracy for c=3: 0.3665\n",
      "Averaged accuracy for c=5: 0.365\n",
      "Best accuracy is 0.3665 with c=3\n",
      "alternative:\n",
      "\tBest attribute loudness - weights=0.655\n",
      "\tWorst attribute speechiness - weights=-0.566\n",
      "blues:\n",
      "\tBest attribute valence - weights=0.962\n",
      "\tWorst attribute energy - weights=-1.141\n",
      "classical:\n",
      "\tBest attribute instrumentalness - weights=1.904\n",
      "\tWorst attribute danceability - weights=-2.800\n",
      "country:\n",
      "\tBest attribute loudness - weights=1.246\n",
      "\tWorst attribute instrumentalness - weights=-2.503\n",
      "electro:\n",
      "\tBest attribute danceability - weights=1.327\n",
      "\tWorst attribute valence - weights=-0.877\n",
      "folk:\n",
      "\tBest attribute acousticness - weights=0.922\n",
      "\tWorst attribute speechiness - weights=-1.242\n",
      "french:\n",
      "\tBest attribute acousticness - weights=1.336\n",
      "\tWorst attribute energy - weights=-0.988\n",
      "hard-rock:\n",
      "\tBest attribute energy - weights=1.152\n",
      "\tWorst attribute danceability - weights=-1.077\n",
      "heavy-metal:\n",
      "\tBest attribute energy - weights=3.963\n",
      "\tWorst attribute acousticness - weights=-3.685\n",
      "hip-hop:\n",
      "\tBest attribute danceability - weights=2.303\n",
      "\tWorst attribute instrumentalness - weights=-1.572\n",
      "indie:\n",
      "\tBest attribute instrumentalness - weights=0.531\n",
      "\tWorst attribute speechiness - weights=-2.236\n",
      "jazz:\n",
      "\tBest attribute acousticness - weights=1.496\n",
      "\tWorst attribute energy - weights=-1.013\n",
      "pop:\n",
      "\tBest attribute loudness - weights=1.697\n",
      "\tWorst attribute energy - weights=-0.918\n",
      "psych-rock:\n",
      "\tBest attribute instrumentalness - weights=1.103\n",
      "\tWorst attribute danceability - weights=-1.953\n",
      "punk-rock:\n",
      "\tBest attribute energy - weights=2.424\n",
      "\tWorst attribute duration_ms - weights=-1.419\n",
      "r-n-b:\n",
      "\tBest attribute loudness - weights=1.246\n",
      "\tWorst attribute energy - weights=-1.263\n",
      "reggae:\n",
      "\tBest attribute speechiness - weights=1.549\n",
      "\tWorst attribute instrumentalness - weights=-1.000\n",
      "rock:\n",
      "\tBest attribute loudness - weights=0.381\n",
      "\tWorst attribute acousticness - weights=-0.845\n",
      "soul:\n",
      "\tBest attribute valence - weights=1.002\n",
      "\tWorst attribute energy - weights=-1.210\n",
      "techno:\n",
      "\tBest attribute danceability - weights=2.292\n",
      "\tWorst attribute loudness - weights=-2.707\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01,0.1,1,2,3,5]\n",
    "max_score = 0\n",
    "best_c = Cs[0]\n",
    "\n",
    "for c in Cs:\n",
    "    model = LogisticRegression(C=c, multi_class='multinomial', solver='newton-cg')\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10, scoring='accuracy'))\n",
    "    print(\"Averaged accuracy for c=\" + str(c) + \": \" + str(score) )\n",
    "    if (score > max_score):\n",
    "        max_score = score\n",
    "        best_c = c\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score) + \" with c=\" + str(best_c))\n",
    "\n",
    "best_model =  LogisticRegression(C=best_c, multi_class='multinomial', solver='newton-cg')\n",
    "best_model_fitted = best_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "indices_max_weights = np.argmax(lr_fitted.coef_, axis=1)\n",
    "indices_min_weights = np.argmin(lr_fitted.coef_, axis=1)\n",
    "\n",
    "for index,genre in enumerate(GENRES):\n",
    "    print('%s:' % genre)\n",
    "    print('\\tBest attribute %s - weights=%0.3f' % (pd_attributes.columns.values[indices_max_weights[index]], lr_fitted.coef_[index][indices_max_weights[index]]))\n",
    "    print('\\tWorst attribute %s - weights=%0.3f' % (pd_attributes.columns.values[indices_min_weights[index]], lr_fitted.coef_[index][indices_min_weights[index]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision tree, default parameters seems to not enhance the result much. \n",
    "\n",
    "Therefore, we just launched it several times to find a maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy is 0.2505\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "for i in range(100):\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "#    print(\"Averaged accuracy: \" + str(score) )\n",
    "    if (score >= max_score):\n",
    "        max_score = score\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Na√Øve Bayes Accuracy: 0.302\n"
     ]
    }
   ],
   "source": [
    "NB_model = GaussianNB()\n",
    "NB_acc_scores = cross_val_score(NB_model, sc_attributes, target_multinomial,cv=10)\n",
    "\n",
    "avg_NB_acc = np.mean(NB_acc_scores)\n",
    "print(\"Averaged Na√Øve Bayes Accuracy: \" + str(avg_NB_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tanh as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.302\n",
      "Averaged accuracy for alpha=1: 0.3255\n",
      "Averaged accuracy for alpha=2: 0.3375\n",
      "Averaged accuracy for alpha=5: 0.3635\n",
      "Averaged accuracy for alpha=10: 0.371\n",
      "Averaged accuracy for alpha=20: 0.3675\n",
      "Best accuracy is 0.371 with alpha=10\n",
      "Averaged accuracy for hidden layer size s=20: 0.3665\n",
      "Averaged accuracy for hidden layer size s=25: 0.371\n",
      "Averaged accuracy for hidden layer size s=30: 0.3675\n",
      "Averaged accuracy for hidden layer size s=50: 0.37\n",
      "Averaged accuracy for hidden layer size s=100: 0.3665\n",
      "Averaged accuracy for hidden layer size s=200: 0.3695\n",
      "Best accuracy is 0.371 with hidden layer size s=25\n",
      "\n",
      "Using identity as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3715\n",
      "Averaged accuracy for alpha=1: 0.3685\n",
      "Averaged accuracy for alpha=2: 0.3665\n",
      "Averaged accuracy for alpha=5: 0.3675\n",
      "Averaged accuracy for alpha=10: 0.364\n",
      "Averaged accuracy for alpha=20: 0.3655\n",
      "Best accuracy is 0.3715 with alpha=0.1\n",
      "Averaged accuracy for hidden layer size s=20: 0.369\n",
      "Averaged accuracy for hidden layer size s=25: 0.3715\n",
      "Averaged accuracy for hidden layer size s=30: 0.37\n",
      "Averaged accuracy for hidden layer size s=50: 0.372\n",
      "Averaged accuracy for hidden layer size s=100: 0.3705\n",
      "Averaged accuracy for hidden layer size s=200: 0.371\n",
      "Best accuracy is 0.372 with hidden layer size s=50\n",
      "\n",
      "Using logistic as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3275\n",
      "Averaged accuracy for alpha=1: 0.3485\n",
      "Averaged accuracy for alpha=2: 0.365\n",
      "Averaged accuracy for alpha=5: 0.365\n",
      "Averaged accuracy for alpha=10: 0.3495\n",
      "Averaged accuracy for alpha=20: 0.3065\n",
      "Best accuracy is 0.365 with alpha=5\n",
      "Averaged accuracy for hidden layer size s=20: 0.3725\n",
      "Averaged accuracy for hidden layer size s=25: 0.365\n",
      "Averaged accuracy for hidden layer size s=30: 0.3685\n",
      "Averaged accuracy for hidden layer size s=50: 0.3705\n",
      "Averaged accuracy for hidden layer size s=100: 0.368\n",
      "Averaged accuracy for hidden layer size s=200: 0.365\n",
      "Best accuracy is 0.3725 with hidden layer size s=20\n",
      "\n",
      "Using relu as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3215\n",
      "Averaged accuracy for alpha=1: 0.3265\n",
      "Averaged accuracy for alpha=2: 0.33\n",
      "Averaged accuracy for alpha=5: 0.346\n",
      "Averaged accuracy for alpha=10: 0.362\n",
      "Averaged accuracy for alpha=20: 0.367\n",
      "Best accuracy is 0.367 with alpha=20\n",
      "Averaged accuracy for hidden layer size s=20: 0.3675\n",
      "Averaged accuracy for hidden layer size s=25: 0.367\n",
      "Averaged accuracy for hidden layer size s=30: 0.363\n",
      "Averaged accuracy for hidden layer size s=50: 0.3665\n",
      "Averaged accuracy for hidden layer size s=100: 0.3645\n",
      "Averaged accuracy for hidden layer size s=200: 0.3675\n",
      "Best accuracy is 0.3675 with hidden layer size s=20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Alphas = [0.1, 1, 2, 5, 10, 20]\n",
    "HLsizes = [20, 25, 30, 50, 100, 200]\n",
    "Activation_functions = ['tanh', 'identity', 'logistic', 'relu']\n",
    "default_alpha = 5\n",
    "default_size = 25\n",
    "\n",
    "for f in Activation_functions:\n",
    "    print(\"Using \" + f + \" as activation function:\")\n",
    "    max_score=0\n",
    "    best_alpha = default_alpha\n",
    "    best_size = default_size\n",
    "    \n",
    "    for a in Alphas:\n",
    "        model = MLPClassifier(hidden_layer_sizes=(best_size,),alpha=a,activation=f, solver='lbfgs', random_state = 1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "        print(\"Averaged accuracy for alpha=\" + str(a) + \": \" + str(score) )\n",
    "        if (score >= max_score):\n",
    "            max_score = score\n",
    "            best_alpha = a\n",
    "    \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with alpha=\" + str(best_alpha))\n",
    "    \n",
    "    max_score = 0\n",
    "    for s in HLsizes:\n",
    "        model = MLPClassifier(hidden_layer_sizes=(s,), alpha=best_alpha, activation=f, solver='lbfgs', random_state = 1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "        print(\"Averaged accuracy for hidden layer size s=\" + str(s) + \": \" + str(score) )\n",
    "        if (score > max_score):\n",
    "            max_score = score\n",
    "            best_size = s\n",
    "    \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with hidden layer size s=\" + str(best_size))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using linear kernel\n",
      "Averaged accuracy for c=0.01: 0.3245\n",
      "Averaged accuracy for c=0.1: 0.3665\n",
      "Averaged accuracy for c=1: 0.3655\n",
      "Averaged accuracy for c=2: 0.3645\n",
      "Averaged accuracy for c=3: 0.366\n",
      "Averaged accuracy for c=5: 0.3645\n",
      "Best accuracy is 0.3665 with c=0.1\n",
      "\n",
      "Using poly kernel\n",
      "Averaged accuracy for c=0.01: 0.1395\n",
      "Averaged accuracy for c=0.1: 0.207\n",
      "Averaged accuracy for c=1: 0.293\n",
      "Averaged accuracy for c=2: 0.302\n",
      "Averaged accuracy for c=3: 0.299\n",
      "Averaged accuracy for c=5: 0.3025\n",
      "Best accuracy is 0.3025 with c=5\n",
      "\n",
      "Using rbf kernel\n",
      "Averaged accuracy for c=0.01: 0.3125\n",
      "Averaged accuracy for c=0.1: 0.3155\n",
      "Averaged accuracy for c=1: 0.346\n",
      "Averaged accuracy for c=2: 0.3445\n",
      "Averaged accuracy for c=3: 0.3415\n",
      "Averaged accuracy for c=5: 0.3315\n",
      "Best accuracy is 0.346 with c=1\n",
      "\n",
      "Using sigmoid kernel\n",
      "Averaged accuracy for c=0.01: 0.277\n",
      "Averaged accuracy for c=0.1: 0.287\n",
      "Averaged accuracy for c=1: 0.2945\n",
      "Averaged accuracy for c=2: 0.29\n",
      "Averaged accuracy for c=3: 0.2855\n",
      "Averaged accuracy for c=5: 0.277\n",
      "Best accuracy is 0.2945 with c=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01,0.1,1,2,3,5]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for k in kernels:\n",
    "    print(\"Using \"+ k + \" kernel\")\n",
    "    max_score = 0\n",
    "    best_c = Cs[0]\n",
    "    for c in Cs:\n",
    "        model = SVC(kernel = k,C=c, random_state=1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10, scoring='accuracy'))\n",
    "        print(\"Averaged accuracy for c=\" + str(c) + \": \" + str(score) )\n",
    "        if (score > max_score):\n",
    "            max_score = score\n",
    "            best_c = c\n",
    "            \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with c=\" + str(best_c)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [the documentation of scikit-learn](http://scikit-learn.org/stable/modules/ensemble.html#parameters), the main parameters to adjust when using these methods are n_estimators and max_features.\n",
    "\n",
    "Besides, it can be seen in the same page that empirical good default value for classification tasks is max_features=sqrt(n_features), which is the default value.\n",
    "\n",
    "Thus, the optimization will only be done over n_estimators.\n",
    "\n",
    "After a first loop, we saw that there is no significan enhancement after n_estimators > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for estimator=50: 0.3585\n",
      "Averaged accuracy for estimator=51: 0.368\n",
      "Averaged accuracy for estimator=52: 0.352\n",
      "Averaged accuracy for estimator=53: 0.355\n",
      "Averaged accuracy for estimator=54: 0.3605\n",
      "Averaged accuracy for estimator=55: 0.3525\n",
      "Averaged accuracy for estimator=56: 0.3625\n",
      "Averaged accuracy for estimator=57: 0.363\n",
      "Averaged accuracy for estimator=58: 0.3585\n",
      "Averaged accuracy for estimator=59: 0.3665\n",
      "Averaged accuracy for estimator=60: 0.363\n",
      "Averaged accuracy for estimator=61: 0.364\n",
      "Averaged accuracy for estimator=62: 0.3595\n",
      "Averaged accuracy for estimator=63: 0.3515\n",
      "Averaged accuracy for estimator=64: 0.36\n",
      "Averaged accuracy for estimator=65: 0.3665\n",
      "Averaged accuracy for estimator=66: 0.357\n",
      "Averaged accuracy for estimator=67: 0.3565\n",
      "Averaged accuracy for estimator=68: 0.3645\n",
      "Averaged accuracy for estimator=69: 0.368\n",
      "Best accuracy is 0.368 with estimator=69\n"
     ]
    }
   ],
   "source": [
    "estimators = range(50, 71, 1)\n",
    "max_score = 0\n",
    "best_estimator = 1\n",
    "\n",
    "for e in estimators:\n",
    "    model = RandomForestClassifier(n_estimators=e)\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "    print(\"Averaged accuracy for estimator=\" + str(e) + \": \" + str(score) )\n",
    "    if (score >= max_score):\n",
    "        max_score = score\n",
    "        best_estimator = e\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score) + \" with estimator=\" + str(best_estimator))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
