{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genrify Project - Phase II\n",
    "## Music genre prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Henri Toussaint<br>\n",
    "Victor Saint Guilhem<br>\n",
    "Benoît Lafon<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project sets out to predict the genre of a music using the Spotify API, which provides audio features for each tracks. To collect the tracks, we used a recommandation function with a genre seed. We handpicked 20 genres in order to best represent tracks, and from each genre, we collected 100 tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from genrify_module import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"music_collection.csv\")\n",
    "#data = data.iloc[np.random.permutation(len(data))]\n",
    "pd_attributes = data.loc[:,'acousticness':'valence']\n",
    "attributes = np.array(pd_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 2000\n",
      "Number of attributes: 13\n",
      "Attributes:\n",
      "\tacousticness\n",
      "\tdanceability\n",
      "\tduration_ms\n",
      "\tenergy\n",
      "\tinstrumentalness\n",
      "\tkey\n",
      "\tliveness\n",
      "\tloudness\n",
      "\tmode\n",
      "\tspeechiness\n",
      "\ttempo\n",
      "\ttime_signature\n",
      "\tvalence\n"
     ]
    }
   ],
   "source": [
    "print('Number of instances: ' + str(data.shape[0]))\n",
    "print('Number of attributes: ' + str(pd_attributes.shape[1]))\n",
    "print('Attributes:')\n",
    "for i in pd_attributes.columns.values:\n",
    "    print('\\t'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We chose the accuraccy measure because blablabla (à remplir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To store the performance of different models\n",
    "global_accuracy_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_attributes = scale(attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENRES = ['alternative','blues','classical','country','electro','folk','french','hard-rock','heavy-metal','hip-hop','indie','jazz','pop','psych-rock','punk-rock','r-n-b','reggae','rock','soul','techno']\n",
    "target_multinomial = []\n",
    "for i in data['genre']:\n",
    "    target_multinomial.append(GENRES.index(i))\n",
    "target_multinomial=np.array(target_multinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Accuracy: 0.0565\n"
     ]
    }
   ],
   "source": [
    "random_model = DummyClassifier(strategy='uniform')\n",
    "\n",
    "random_acc_scores = cross_val_score(random_model, sc_attributes, target_multinomial,cv=10)\n",
    "avg_random_acc = np.mean(random_acc_scores)\n",
    "print(\"Averaged Accuracy: \" + str(avg_random_acc))\n",
    "global_accuracy_scores[\"Random\"] = avg_random_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Accuracy: 0.05\n"
     ]
    }
   ],
   "source": [
    "majo_model = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "majo_acc_scores = cross_val_score(majo_model, sc_attributes, target_multinomial,cv=10)\n",
    "avg_majo_acc = np.mean(majo_acc_scores)\n",
    "print(\"Averaged Accuracy: \" + str(avg_majo_acc))\n",
    "global_accuracy_scores[\"Majority Class \"] = avg_majo_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for c=0.01: 0.335\n",
      "Averaged accuracy for c=0.1: 0.359\n",
      "Averaged accuracy for c=10: 0.365\n",
      "Averaged accuracy for c=20: 0.3675\n",
      "Averaged accuracy for c=30: 0.3685\n",
      "Averaged accuracy for c=40: 0.37\n",
      "Averaged accuracy for c=50: 0.37\n",
      "Averaged accuracy for c=60: 0.37\n",
      "Averaged accuracy for c=70: 0.37\n",
      "Averaged accuracy for c=80: 0.3705\n",
      "Averaged accuracy for c=90: 0.3705\n",
      "Averaged accuracy for c=100: 0.3705\n",
      "Averaged accuracy for c=110: 0.3705\n",
      "Averaged accuracy for c=120: 0.3705\n",
      "Averaged accuracy for c=130: 0.371\n",
      "Averaged accuracy for c=140: 0.371\n",
      "Averaged accuracy for c=150: 0.371\n",
      "Averaged accuracy for c=160: 0.37\n",
      "Averaged accuracy for c=170: 0.371\n",
      "Averaged accuracy for c=180: 0.3705\n",
      "Averaged accuracy for c=190: 0.3705\n",
      "Averaged accuracy for c=200: 0.3705\n",
      "Averaged accuracy for c=210: 0.3705\n",
      "Averaged accuracy for c=220: 0.3705\n",
      "Averaged accuracy for c=230: 0.3705\n",
      "Averaged accuracy for c=240: 0.3705\n",
      "Averaged accuracy for c=250: 0.3705\n",
      "Averaged accuracy for c=260: 0.3705\n",
      "Averaged accuracy for c=270: 0.3705\n",
      "Averaged accuracy for c=280: 0.3705\n",
      "Averaged accuracy for c=290: 0.3705\n",
      "Averaged accuracy for c=300: 0.3705\n",
      "Best accuracy is 0.371 with c=170\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01, 0.1]\n",
    "Cs.extend(range(10, 310, 10))\n",
    "max_score = 0\n",
    "best_c = Cs[0]\n",
    "\n",
    "for c in Cs:\n",
    "    model = LogisticRegression(C=c, multi_class='multinomial', solver='newton-cg', random_state=1)\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10, scoring='accuracy'))\n",
    "    print(\"Averaged accuracy for c=\" + str(c) + \": \" + str(score) )\n",
    "    if (score > max_score):\n",
    "        max_score = score\n",
    "        best_c = c\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score) + \" with c=\" + str(best_c))\n",
    "global_accuracy_scores[\"Logistic Regression \"] = max_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision tree, default parameters seems to not enhance the result much. \n",
    "\n",
    "Therefore, we just launched it several times to find a maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy is 0.2475\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "for i in range(100):\n",
    "    model = tree.DecisionTreeClassifier()\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "#    print(\"Averaged accuracy: \" + str(score) )\n",
    "    if (score >= max_score):\n",
    "        max_score = score\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score))\n",
    "global_accuracy_scores[\"Decision Tree \"] = max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Naïve Bayes Accuracy: 0.302\n"
     ]
    }
   ],
   "source": [
    "NB_model = GaussianNB()\n",
    "NB_acc_scores = cross_val_score(NB_model, sc_attributes, target_multinomial,cv=10)\n",
    "\n",
    "avg_NB_acc = np.mean(NB_acc_scores)\n",
    "print(\"Averaged Naïve Bayes Accuracy: \" + str(avg_NB_acc))\n",
    "global_accuracy_scores[\"Naive Bayes\"] = max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tanh as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3035\n",
      "Averaged accuracy for alpha=1: 0.326\n",
      "Averaged accuracy for alpha=2: 0.338\n",
      "Averaged accuracy for alpha=5: 0.3635\n",
      "Averaged accuracy for alpha=10: 0.3705\n",
      "Averaged accuracy for alpha=20: 0.3675\n",
      "Best accuracy is 0.3705 with alpha=10\n",
      "Averaged accuracy for hidden layer size s=20: 0.3675\n",
      "Averaged accuracy for hidden layer size s=25: 0.3705\n",
      "Averaged accuracy for hidden layer size s=30: 0.366\n",
      "Averaged accuracy for hidden layer size s=50: 0.368\n",
      "Averaged accuracy for hidden layer size s=100: 0.368\n",
      "Averaged accuracy for hidden layer size s=200: 0.369\n",
      "Best accuracy is 0.3705 with hidden layer size s=25\n",
      "Using identity as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.372\n",
      "Averaged accuracy for alpha=1: 0.3685\n",
      "Averaged accuracy for alpha=2: 0.3675\n",
      "Averaged accuracy for alpha=5: 0.366\n",
      "Averaged accuracy for alpha=10: 0.364\n",
      "Averaged accuracy for alpha=20: 0.3655\n",
      "Best accuracy is 0.372 with alpha=0.1\n",
      "Averaged accuracy for hidden layer size s=20: 0.3695\n",
      "Averaged accuracy for hidden layer size s=25: 0.372\n",
      "Averaged accuracy for hidden layer size s=30: 0.3705\n",
      "Averaged accuracy for hidden layer size s=50: 0.372\n",
      "Averaged accuracy for hidden layer size s=100: 0.3705\n",
      "Averaged accuracy for hidden layer size s=200: 0.371\n",
      "Best accuracy is 0.372 with hidden layer size s=25\n",
      "Using logistic as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3285\n",
      "Averaged accuracy for alpha=1: 0.3475\n",
      "Averaged accuracy for alpha=2: 0.365\n",
      "Averaged accuracy for alpha=5: 0.365\n",
      "Averaged accuracy for alpha=10: 0.35\n",
      "Averaged accuracy for alpha=20: 0.3065\n",
      "Best accuracy is 0.365 with alpha=5\n",
      "Averaged accuracy for hidden layer size s=20: 0.3715\n",
      "Averaged accuracy for hidden layer size s=25: 0.365\n",
      "Averaged accuracy for hidden layer size s=30: 0.3665\n",
      "Averaged accuracy for hidden layer size s=50: 0.3705\n",
      "Averaged accuracy for hidden layer size s=100: 0.368\n",
      "Averaged accuracy for hidden layer size s=200: 0.365\n",
      "Best accuracy is 0.3715 with hidden layer size s=20\n",
      "Using relu as activation function:\n",
      "Averaged accuracy for alpha=0.1: 0.3225\n",
      "Averaged accuracy for alpha=1: 0.3285\n",
      "Averaged accuracy for alpha=2: 0.329\n",
      "Averaged accuracy for alpha=5: 0.3485\n",
      "Averaged accuracy for alpha=10: 0.3625\n",
      "Averaged accuracy for alpha=20: 0.366\n",
      "Best accuracy is 0.366 with alpha=20\n",
      "Averaged accuracy for hidden layer size s=20: 0.3675\n",
      "Averaged accuracy for hidden layer size s=25: 0.366\n",
      "Averaged accuracy for hidden layer size s=30: 0.362\n",
      "Averaged accuracy for hidden layer size s=50: 0.366\n",
      "Averaged accuracy for hidden layer size s=100: 0.3645\n",
      "Averaged accuracy for hidden layer size s=200: 0.367\n",
      "Best accuracy is 0.3675 with hidden layer size s=20\n",
      "\n",
      "The best final accuracy is 0.372 with a hidden layer size of s=25 and alpha=0.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Alphas = [0.1, 1, 2, 5, 10, 20]\n",
    "HLsizes = [20, 25, 30, 50, 100, 200]\n",
    "Activation_functions = ['tanh', 'identity', 'logistic', 'relu']\n",
    "default_alpha = 5\n",
    "default_size = 25\n",
    "final_score = 0\n",
    "final_alpha = 0\n",
    "final_size = 0\n",
    "\n",
    "for f in Activation_functions:\n",
    "    print(\"\\nUsing \" + f + \" as activation function:\")\n",
    "    max_score=0\n",
    "    best_alpha = default_alpha\n",
    "    best_size = default_size\n",
    "    \n",
    "    for a in Alphas:\n",
    "        model = MLPClassifier(hidden_layer_sizes=(best_size,),alpha=a,activation=f, solver='lbfgs', random_state = 1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "        print(\"Averaged accuracy for alpha=\" + str(a) + \": \" + str(score) )\n",
    "        if (score >= max_score):\n",
    "            max_score = score\n",
    "            best_alpha = a\n",
    "    \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with alpha=\" + str(best_alpha))\n",
    "    \n",
    "    max_score = 0\n",
    "    for s in HLsizes:\n",
    "        model = MLPClassifier(hidden_layer_sizes=(s,), alpha=best_alpha, activation=f, solver='lbfgs', random_state = 1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "        print(\"Averaged accuracy for hidden layer size s=\" + str(s) + \": \" + str(score) )\n",
    "        if (score > max_score):\n",
    "            max_score = score\n",
    "            best_size = s\n",
    "    \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with hidden layer size s=\" + str(best_size))\n",
    "    if (max_score > final_score):\n",
    "        final_score = max_score\n",
    "        final_alpha = best_alpha\n",
    "        final_size = best_size\n",
    "\n",
    "print(\"\\nThe best final accuracy is \" + str(final_score) + \" with a hidden layer size of s=\" + str(final_size) + \" and alpha=\" + str(final_alpha)+ \".\\n\")\n",
    "global_accuracy_scores[\"Neural Networks\"] = final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using linear kernel\n",
      "Averaged accuracy for c=0.01: 0.3245\n",
      "Averaged accuracy for c=0.1: 0.3665\n",
      "Averaged accuracy for c=1: 0.3655\n",
      "Averaged accuracy for c=2: 0.3645\n",
      "Averaged accuracy for c=3: 0.366\n",
      "Averaged accuracy for c=5: 0.3645\n",
      "Best accuracy is 0.3665 with c=0.1\n",
      "\n",
      "Using poly kernel\n",
      "Averaged accuracy for c=0.01: 0.1395\n",
      "Averaged accuracy for c=0.1: 0.207\n",
      "Averaged accuracy for c=1: 0.293\n",
      "Averaged accuracy for c=2: 0.302\n",
      "Averaged accuracy for c=3: 0.299\n",
      "Averaged accuracy for c=5: 0.3025\n",
      "Best accuracy is 0.3025 with c=5\n",
      "\n",
      "Using rbf kernel\n",
      "Averaged accuracy for c=0.01: 0.3125\n",
      "Averaged accuracy for c=0.1: 0.3155\n",
      "Averaged accuracy for c=1: 0.346\n",
      "Averaged accuracy for c=2: 0.3445\n",
      "Averaged accuracy for c=3: 0.3415\n",
      "Averaged accuracy for c=5: 0.3315\n",
      "Best accuracy is 0.346 with c=1\n",
      "\n",
      "Using sigmoid kernel\n",
      "Averaged accuracy for c=0.01: 0.277\n",
      "Averaged accuracy for c=0.1: 0.287\n",
      "Averaged accuracy for c=1: 0.2945\n",
      "Averaged accuracy for c=2: 0.29\n",
      "Averaged accuracy for c=3: 0.2855\n",
      "Averaged accuracy for c=5: 0.277\n",
      "Best accuracy is 0.2945 with c=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01,0.1,1,2,3,5]\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for k in kernels:\n",
    "    print(\"Using \"+ k + \" kernel\")\n",
    "    max_score = 0\n",
    "    best_c = Cs[0]\n",
    "    for c in Cs:\n",
    "        model = SVC(kernel = k,C=c, random_state=1)\n",
    "        score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10, scoring='accuracy'))\n",
    "        print(\"Averaged accuracy for c=\" + str(c) + \": \" + str(score) )\n",
    "        if (score > max_score):\n",
    "            max_score = score\n",
    "            best_c = c\n",
    "            \n",
    "    print(\"Best accuracy is \"+ str(max_score) + \" with c=\" + str(best_c)+\"\\n\")\n",
    "\n",
    "global_accuracy_scores[\"Support Vector Machine\"] = max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [the documentation of scikit-learn](http://scikit-learn.org/stable/modules/ensemble.html#parameters), the main parameters to adjust when using these methods are n_estimators and max_features.\n",
    "\n",
    "Besides, it can be seen in the same page that empirical good default value for classification tasks is max_features=sqrt(n_features), which is the default value.\n",
    "\n",
    "Thus, the optimization will only be done over n_estimators.\n",
    "\n",
    "After a first loop, we saw that there is no significan enhancement after n_estimators > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged accuracy for estimator=50: 0.3545\n",
      "Averaged accuracy for estimator=51: 0.356\n",
      "Averaged accuracy for estimator=52: 0.3495\n",
      "Averaged accuracy for estimator=53: 0.348\n",
      "Averaged accuracy for estimator=54: 0.353\n",
      "Averaged accuracy for estimator=55: 0.3505\n",
      "Averaged accuracy for estimator=56: 0.3515\n",
      "Averaged accuracy for estimator=57: 0.3495\n",
      "Averaged accuracy for estimator=58: 0.352\n",
      "Averaged accuracy for estimator=59: 0.3515\n",
      "Averaged accuracy for estimator=60: 0.352\n",
      "Averaged accuracy for estimator=61: 0.351\n",
      "Averaged accuracy for estimator=62: 0.352\n",
      "Averaged accuracy for estimator=63: 0.354\n",
      "Averaged accuracy for estimator=64: 0.356\n",
      "Averaged accuracy for estimator=65: 0.3555\n",
      "Averaged accuracy for estimator=66: 0.3525\n",
      "Averaged accuracy for estimator=67: 0.356\n",
      "Averaged accuracy for estimator=68: 0.3595\n",
      "Averaged accuracy for estimator=69: 0.359\n",
      "Averaged accuracy for estimator=70: 0.361\n",
      "Best accuracy is 0.361 with estimator=70\n"
     ]
    }
   ],
   "source": [
    "estimators = range(50, 71, 1)\n",
    "max_score = 0\n",
    "best_estimator = 1\n",
    "\n",
    "for e in estimators:\n",
    "    model = RandomForestClassifier(n_estimators=e, random_state=1)\n",
    "    score = np.mean(cross_val_score(model, sc_attributes, target_multinomial,cv=10))\n",
    "    print(\"Averaged accuracy for estimator=\" + str(e) + \": \" + str(score) )\n",
    "    if (score >= max_score):\n",
    "        max_score = score\n",
    "        best_estimator = e\n",
    "\n",
    "print(\"Best accuracy is \"+ str(max_score) + \" with estimator=\" + str(best_estimator))\n",
    "global_accuracy_scores[\"Random Forest\"] = max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 8 artists>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFuCAYAAAB6GVitAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10df748d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks(range(len(global_accuracy_scores)), global_accuracy_scores.keys(), rotation=90)\n",
    "plt.bar(range(len(global_accuracy_scores)), global_accuracy_scores.values(), align='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that best fits our data is Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr_best_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5b25ad2cadf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_multinomial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.67\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_best_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_model_fitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr_best_c' is not defined"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(sc_attributes, target_multinomial, train_size=0.67, random_state=1)\n",
    "\n",
    "best_model =  LogisticRegression(C=lr_best_c, multi_class='multinomial', solver='newton-cg')\n",
    "best_model_fitted = best_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "indices_max_weights = np.argmax(best_model_fitted.coef_, axis=1)\n",
    "indices_min_weights = np.argmin(best_model_fitted.coef_, axis=1)\n",
    "\n",
    "for index,genre in enumerate(GENRES):\n",
    "    print('%s:' % genre)\n",
    "    print('\\tBest attribute %s - weights=%0.3f' % (pd_attributes.columns.values[indices_max_weights[index]], best_model_fitted.coef_[index][indices_max_weights[index]]))\n",
    "    print('\\tWorst attribute %s - weights=%0.3f' % (pd_attributes.columns.values[indices_min_weights[index]], best_model_fitted.coef_[index][indices_min_weights[index]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
